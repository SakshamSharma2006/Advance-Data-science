{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vskdY8HTDK7e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Dataset path\n",
        "# ----------------------------\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"andradaolteanu/gtzan-dataset-music-genre-classification\")\n",
        "print(\"Base dataset path:\", path)\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Auto-detect image folder\n",
        "# ----------------------------\n",
        "image_path = None\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for d in dirs:\n",
        "        if \"image\" in d.lower():  # finds \"images_original\" or similar\n",
        "            image_path = os.path.join(root, d)\n",
        "            break\n",
        "    if image_path:\n",
        "        break\n",
        "\n",
        "if not image_path:\n",
        "    raise FileNotFoundError(\"❌ No image folder found in dataset!\")\n",
        "\n",
        "print(\"✅ Found image folder:\", image_path)\n",
        "print(\"Genres:\", os.listdir(image_path))\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Image Data Generators\n",
        "# ----------------------------\n",
        "img_size = (128, 128)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    image_path,\n",
        "    target_size=img_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    image_path,\n",
        "    target_size=img_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 4. CNN Model\n",
        "# ----------------------------\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_gen.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Train\n",
        "# ----------------------------\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=15,\n",
        "    validation_data=val_gen\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Plot Accuracy & Loss\n",
        "# ----------------------------\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# 7. Confusion Matrix\n",
        "# ----------------------------\n",
        "Y_pred = model.predict(val_gen)\n",
        "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "Y_true = val_gen.classes\n",
        "\n",
        "cm = confusion_matrix(Y_true, Y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=list(train_gen.class_indices.keys()),\n",
        "            yticklabels=list(train_gen.class_indices.keys()))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    }
  ]
}