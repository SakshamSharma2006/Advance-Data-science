{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abd7VQcuF-WI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Example model with L1 Regularization\n",
        "def create_model_l1(l1_strength=0.01):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1(l1_strength), input_shape=(784,)),\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1(l1_strength)),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Example model with L2 Regularization\n",
        "def create_model_l2(l2_strength=0.01):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2_strength), input_shape=(784,)),\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2_strength)),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Example model with Elastic Net Regularization (L1 + L2)\n",
        "def create_model_elastic_net(l1_strength=0.01, l2_strength=0.01):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_strength, l2=l2_strength), input_shape=(784,)),\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_strength, l2=l2_strength)),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Example model with Dropout Regularization\n",
        "def create_model_dropout(dropout_rate=0.5):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Example model with Early Stopping\n",
        "def create_model_early_stopping():\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# Data Preparation (MNIST)\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0  # Normalize images to [0, 1]\n",
        "X_train = X_train.reshape(-1, 784)  # Flatten 28x28 images into vectors\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "# Testing each model\n",
        "print(\"Testing L1 Regularization Model:\")\n",
        "model_l1 = create_model_l1()\n",
        "model_l1.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "model_l1.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"\\nTesting L2 Regularization Model:\")\n",
        "model_l2 = create_model_l2()\n",
        "model_l2.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "model_l2.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"\\nTesting Elastic Net Regularization Model:\")\n",
        "model_elastic_net = create_model_elastic_net()\n",
        "model_elastic_net.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "model_elastic_net.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"\\nTesting Dropout Regularization Model:\")\n",
        "model_dropout = create_model_dropout()\n",
        "model_dropout.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "model_dropout.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"\\nTesting Early Stopping Model:\")\n",
        "model_early_stopping = create_model_early_stopping()\n",
        "model_early_stopping.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "model_early_stopping.evaluate(X_test, y_test)\n"
      ]
    }
  ]
}