{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jckETq8TXAcf"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# GTZAN Seq2Seq (Encoder–Decoder) with Multi-Timestep Outputs\n",
        "# Works with features_3_sec.csv (57 features) and auto-handles reshape\n",
        "# ===============================\n",
        "\n",
        "# Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# ---------- Load dataset ----------\n",
        "data = pd.read_csv(\"features_3_sec.csv\")\n",
        "drop_cols = [c for c in [\"filename\", \"length\", \"label\"] if c in data.columns]\n",
        "feature_cols = [c for c in data.columns if c not in drop_cols]\n",
        "X = data[feature_cols].values            # (samples, n_features)\n",
        "y = data[\"label\"].values\n",
        "\n",
        "print(f\"Dataset shape: {data.shape}\")\n",
        "print(f\"Features used: {len(feature_cols)} -> {feature_cols[:5]} ...\")\n",
        "print(\"Genres:\", sorted(data[\"label\"].unique()))\n",
        "\n",
        "# ---------- Encode labels ----------\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "n_classes = len(le.classes_)\n",
        "print(\"Number of classes:\", n_classes)\n",
        "\n",
        "# ---------- Scale features (before reshape) ----------\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "n_samples, n_features = X_scaled.shape\n",
        "\n",
        "# ---------- Choose a valid (timesteps, features_per_step) ----------\n",
        "def pick_sequence_shape(n_feats):\n",
        "    # Prefer a reasonable number of timesteps, but must divide n_feats exactly\n",
        "    preferred = [32, 30, 29, 28, 24, 20, 19, 16, 15, 12, 10, 8, 6, 4, 3, 2]\n",
        "    for t in preferred:\n",
        "        if n_feats % t == 0:\n",
        "            return t, n_feats // t\n",
        "    # Fallback: every feature is a timestep\n",
        "    return n_feats, 1\n",
        "\n",
        "timesteps, features_per_step = pick_sequence_shape(n_features)\n",
        "print(f\"Chosen sequence shape -> timesteps={timesteps}, features_per_step={features_per_step}\")\n",
        "\n",
        "# Reshape to sequences\n",
        "X_seq = X_scaled.reshape(n_samples, timesteps, features_per_step)\n",
        "print(\"X_seq shape:\", X_seq.shape)   # e.g., (9990, 19, 3) for 57 features\n",
        "\n",
        "# ---------- Train/Test split ----------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_seq, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
        ")\n",
        "\n",
        "# ---------- Build decoder targets (multi-timestep) ----------\n",
        "# Repeat the one-hot label across all decoder timesteps\n",
        "y_train_1h = to_categorical(y_train, num_classes=n_classes)  # (N, C)\n",
        "y_test_1h  = to_categorical(y_test,  num_classes=n_classes)\n",
        "\n",
        "y_train_seq = np.repeat(y_train_1h[:, None, :], timesteps, axis=1)  # (N, T, C)\n",
        "y_test_seq  = np.repeat(y_test_1h[:,  None, :], timesteps, axis=1)\n",
        "\n",
        "# Teacher forcing inputs: shift right, zero at t=0 as <START>\n",
        "dec_in_train = np.zeros_like(y_train_seq)\n",
        "dec_in_train[:, 1:, :] = y_train_seq[:, :-1, :]\n",
        "dec_in_test  = np.zeros_like(y_test_seq)\n",
        "dec_in_test[:, 1:, :]  = y_test_seq[:, :-1, :]\n",
        "\n",
        "print(\"Decoder target shape:\", y_train_seq.shape)\n",
        "print(\"Decoder input shape:\", dec_in_train.shape)\n",
        "\n",
        "# ---------- Encoder–Decoder model ----------\n",
        "enc_inputs = tf.keras.Input(shape=(timesteps, features_per_step), name=\"encoder_inputs\")\n",
        "# Encoder\n",
        "enc_lstm = tf.keras.layers.LSTM(128, return_state=True, name=\"encoder_lstm\")\n",
        "_, state_h, state_c = enc_lstm(enc_inputs)\n",
        "enc_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "dec_inputs = tf.keras.Input(shape=(timesteps, n_classes), name=\"decoder_inputs\")\n",
        "dec_lstm = tf.keras.layers.LSTM(128, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
        "dec_outputs, _, _ = dec_lstm(dec_inputs, initial_state=enc_states)\n",
        "dec_outputs = tf.keras.layers.Dropout(0.3)(dec_outputs)\n",
        "dec_dense = tf.keras.layers.Dense(n_classes, activation=\"softmax\", name=\"decoder_dense\")\n",
        "dec_outputs = dec_dense(dec_outputs)\n",
        "\n",
        "model = tf.keras.Model([enc_inputs, dec_inputs], dec_outputs)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "# ---------- Callbacks ----------\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=12,\n",
        "                                     restore_best_weights=True, min_delta=1e-3),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7,\n",
        "                                         patience=6, min_lr=1e-6, verbose=1),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"best_seq2seq_genre.keras\",\n",
        "                                       monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n",
        "]\n",
        "\n",
        "# ---------- Train ----------\n",
        "history = model.fit(\n",
        "    [X_train, dec_in_train], y_train_seq,\n",
        "    validation_data=([X_test, dec_in_test], y_test_seq),\n",
        "    epochs=60, batch_size=64, callbacks=callbacks, verbose=1\n",
        ")\n",
        "\n",
        "# ---------- Evaluate ----------\n",
        "loss, acc = model.evaluate([X_test, dec_in_test], y_test_seq, verbose=0)\n",
        "print(f\"\\nTest accuracy (per-step): {acc:.4f}  |  loss: {loss:.4f}\")\n",
        "\n",
        "# ---------- Step-wise predictions -> collapse to single class via majority vote ----------\n",
        "y_pred_seq = model.predict([X_test, dec_in_test], verbose=0)     # (N, T, C)\n",
        "y_pred_steps = np.argmax(y_pred_seq, axis=-1)                    # (N, T)\n",
        "# majority vote across timesteps\n",
        "y_pred_final = np.array([np.bincount(seq).argmax() for seq in y_pred_steps])\n",
        "y_true_final = y_test\n",
        "\n",
        "print(\"\\nClassification Report (majority vote across timesteps):\")\n",
        "print(classification_report(y_true_final, y_pred_final, target_names=le.classes_))\n",
        "\n",
        "# ---------- Confusion matrix ----------\n",
        "cm = confusion_matrix(y_true_final, y_pred_final)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix (Majority Vote)\")\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "# ---------- Save final model ----------\n",
        "model.save(\"seq2seq_gtzan_multi_timestep.keras\")\n",
        "print(\"\\n✅ Saved model: seq2seq_gtzan_multi_timestep.keras\")\n"
      ]
    }
  ]
}